{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport lightgbm as lgb\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')\n\npath = '../input/'\n\ndtypes = {\n        'ip'            : 'uint32',\n        'app'           : 'uint16',\n        'device'        : 'uint16',\n        'os'            : 'uint16',\n        'channel'       : 'uint16',\n        'is_attributed' : 'uint8',\n        'click_id'      : 'uint32'\n        }\n\nreading_cols_train = ['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\nreading_cols_test =  ['ip','app','device','os', 'channel', 'click_time', 'click_id']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b020cf4df1dcf45fee62e4f3d8388a20dcfffb6","_cell_guid":"60ce4edb-5b70-4e71-a31f-e68ee02253c3"},"cell_type":"markdown","source":"# Features"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":false},"cell_type":"code","source":"target = 'is_attributed'\ncategoricals = ['app', 'device', 'os', 'channel', 'hour', 'day']\npredictors =   ['app', 'device', 'os', 'channel', 'hour', 'day', 'next_click']\n\ndef df_add_counts(df, cols):\n    arr_slice = df[cols].values\n    unq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1),\n                                     return_inverse=True, return_counts=True)\n    df[\"_\".join(cols)+'_count'] = counts[unqtags]\n    predictors.append(\"_\".join(cols)+'_count')\n\ndef df_add_cum_counts(df, cols):\n    df[\"_\".join(cols)+'_cum_count']=df.groupby(cols).cumcount()\n    predictors.append(\"_\".join(cols)+'_cum_count')\n    \ndef df_transform(df):\n    df.reset_index(drop=True, inplace=True)\n    with timer(\"Adding counts\"):\n        df['click_time']= pd.to_datetime(df['click_time'])\n        dt= df['click_time'].dt\n        df['day'] = dt.day.astype('uint8')\n        df['hour'] = dt.hour.astype('uint8')\n        del(dt)\n        df_add_counts(df, ['ip', 'day', 'hour'])\n        df_add_counts(df, ['ip', 'app'])\n        df_add_counts(df, ['ip', 'app', 'os'])\n        df_add_counts(df, ['ip', 'device'])\n        df_add_counts(df, ['app', 'channel'])\n        df_add_counts(df, ['ip', 'device','os'])\n        df_add_counts(df, ['ip', 'device','os','app'])\n        df_add_cum_counts(df, ['ip', 'device','os'])\n        df_add_cum_counts(df, ['ip', 'device','os','app'])\n    with timer(\"Adding next click times\"):\n        D= 2**26\n        df['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n                         + \"_\" + df['os'].astype(str)).apply(hash) % D\n        click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n        df['epochtime']= df['click_time'].astype(np.int64) // 10 ** 9\n        next_clicks= []\n        for category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n            next_clicks.append(click_buffer[category]-time)\n            click_buffer[category]= time\n        del(click_buffer)\n        df['next_click']= list(reversed(next_clicks))\n        df.drop(['click_time','category','epochtime'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ef1a5ed07bbab4becafca881ef5fd34ebb4abec","_cell_guid":"8557c554-a456-42f5-b7cd-0e3b00d84979"},"cell_type":"markdown","source":"# Model"},{"metadata":{"_uuid":"daf788e7fd0a6c740d7f3694bac2e574fe06cf63","collapsed":true,"_cell_guid":"3cfcda95-1f72-4e95-b592-d5bb1768941f","trusted":false},"cell_type":"code","source":"num_boost_round = 2000\nearly_stopping_rounds = 50\nverbose_eval = 10\n\nparams = {\n    'learning_rate': 0.1,\n    #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n    'num_leaves': 7,  # 2^max_depth - 1\n    'max_depth': 4,  # -1 means no limit\n    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n    'max_bin': 100,  # Number of bucketed bin for feature values\n    'subsample': 0.7,  # Subsample ratio of the training instance.\n    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n    'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n    'min_split_gain' : 0,\n    'scale_pos_weight':99.7, # because training data is extremely unbalanced \n\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'subsample_for_bin': 200000,  # Number of samples for constructing bin\n    'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n    'reg_alpha': 0,  # L1 regularization term on weights\n    'reg_lambda': 0,  # L2 regularization term on weights\n    'nthread': 4,\n    'verbose': 0,\n}\n\ndef lgb_modelfit_nocv(xgtrain, xgvalid, predictors,feval=None, \n                      early_stopping_rounds=early_stopping_rounds, \n                      num_boost_round=num_boost_round, \n                      verbose_eval=verbose_eval):\n\n    evals_results = {}\n\n    bst1 = lgb.train(params,\n                     xgtrain, \n                     valid_sets=[xgtrain, xgvalid], \n                     valid_names=['train','valid'], \n                     evals_result=evals_results, \n                     num_boost_round=num_boost_round,\n                     early_stopping_rounds=early_stopping_rounds,\n                     verbose_eval=verbose_eval, \n                     feval=feval)\n\n    return bst1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f7b828425fb2a3636620ec11dd7ac654236dd8c","_cell_guid":"155d0d52-6281-45ae-a4c6-88929a137d9e"},"cell_type":"markdown","source":"# Train"},{"metadata":{"_uuid":"31223983cc1ca0125ae920324444bfe18a60380f","_cell_guid":"1fefbc96-850a-4900-ad11-9a7d644ec336","trusted":false,"collapsed":true},"cell_type":"code","source":"TESTING = False\n\nif TESTING : NROWS =  1000000\nelse :       NROWS = 40000000\n\nTOTAL_ROWS = 184903890\nSKIP_ROWS = TOTAL_ROWS-NROWS\n\nprint('loading train data...')\ntrain = pd.read_csv(path+\"train.csv\", skiprows=range(1,SKIP_ROWS+1), nrows=NROWS, dtype=dtypes, usecols=reading_cols_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c85afef9141849bca69a305254d1b16de4489f7","_cell_guid":"36daf99e-ab02-4661-a5e8-f26400db0c28","trusted":false,"collapsed":true},"cell_type":"code","source":"print('creating new features...')\ndf_transform(train)\nprint('predictors : \\n - '+'\\n - '.join(predictors))\n\nprint('\\ntrain_test_split...')\ntrain_df, val_df = train_test_split(train, test_size=0.05, random_state=0)\ndel train\ngc.collect()\nprint(\"train size: \", len(train_df))\nprint(\"valid size: \", len(val_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07449ce9fe398182a154aa768b37987477258d00","_cell_guid":"dae80864-f91f-4366-829a-71191f231405","trusted":false,"collapsed":true},"cell_type":"code","source":"print('creating LGB dataset...')\nxgtrain = lgb.Dataset(train_df[predictors].values, label=train_df[target].values,\n                      feature_name=predictors,categorical_feature=categoricals)\nxgvalid = lgb.Dataset(val_df[predictors].values, label=val_df[target].values,\n                      feature_name=predictors,categorical_feature=categoricals)\ndel train_df\ndel val_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74b1c784d32775e5b16ff57e30b38d03dd37c3ea","_cell_guid":"507d848c-d5fd-4b5f-904e-5d904f733877","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"Training...\")\nbst = lgb_modelfit_nocv(xgtrain, xgvalid, predictors)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a5975f98c6f75bf9491afa26ab24645cc40708d","_cell_guid":"ef1286ea-d4b2-44cc-b59b-9a7416040291","trusted":false,"collapsed":true},"cell_type":"code","source":"del xgtrain\ndel xgvalid\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcf0cb9cc1ac0e58f1eba1a13534964f3224dc31","_cell_guid":"920a4cce-f257-46da-bb4e-18361e75099a"},"cell_type":"markdown","source":"# Predict"},{"metadata":{"_uuid":"5aa8c7db613a3b810e4d41bd609b4f4fa5b26918","_cell_guid":"83891d83-20fe-44b0-9c24-9dfcc862a137","trusted":false,"collapsed":true},"cell_type":"code","source":"print('loading test data and creating new features...')\ntest = pd.read_csv(path+\"test.csv\", dtype=dtypes, usecols=reading_cols_test)\ndf_transform(test)\n\nsub = pd.DataFrame()\nsub['click_id'] = test['click_id'].astype('int')\n\nprint(\"predicting...\")\nsub['is_attributed'] = bst.predict(test[predictors])\ndel test\ngc.collect()\n\nprint(\"writing...\")\nsub.to_csv('sub_lightGBM_py.csv',index=False)\nprint(\"done...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3124417a2350bbed923ca0b2218ed7d58d239d2d","collapsed":true,"_cell_guid":"df796a57-184c-4c92-84d8-504d3faa3c0f","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb7457240ffc373a6b9c5ef7e1f7b90bb231767f","collapsed":true,"_cell_guid":"51ad2432-56f6-45b2-85a7-32c832ba521c","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}